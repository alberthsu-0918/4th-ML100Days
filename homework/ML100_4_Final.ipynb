{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loda image\n",
    "path_daisy = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/daisy/'\n",
    "path_dandelion = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/dandelion/'\n",
    "path_rose = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/rose/'\n",
    "path_sunflower = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/sunflower/'\n",
    "path_tulip = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/tulip/'\n",
    "\n",
    "\n",
    "daisy = os.listdir(path_daisy)\n",
    "dandelion = os.listdir(path_dandelion)\n",
    "rose = os.listdir(path_rose)\n",
    "sunflower = os.listdir(path_sunflower)\n",
    "tulip = os.listdir(path_tulip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crate Lable array y \n",
    "y_daisy = [0]*len(daisy)\n",
    "y_dandelion = [1]*len(dandelion)\n",
    "y_rose = [2]*len(rose)\n",
    "y_sunflower = [3]*len(sunflower)\n",
    "y_tulip = [4]*len(tulip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823\n"
     ]
    }
   ],
   "source": [
    "#Load image to arrays\n",
    "img_flowers = []\n",
    "img_dandelion = np.zeros((len(dandelion),1))\n",
    "img_rose = np.zeros((len(rose),1))\n",
    "img_sunflower = np.zeros((len(sunflower),1))\n",
    "img_tulip = np.zeros((len(tulip),1))\n",
    "\n",
    "Downsize = 256\n",
    "\n",
    "i = 0\n",
    "for i in range(len(daisy)):\n",
    "    pic = cv2.imread(path_daisy+daisy[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(dandelion)):\n",
    "    pic = cv2.imread(path_dandelion+dandelion[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(rose)):\n",
    "    pic = cv2.imread(path_rose+rose[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(sunflower)):\n",
    "    pic = cv2.imread(path_sunflower+sunflower[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(tulip)):\n",
    "    pic = cv2.imread(path_tulip+tulip[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "\n",
    "    \n",
    "print(len(img_flowers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data(img_flowers) and Label(y___)\n",
    "\n",
    "Y = y_daisy+y_dandelion+y_rose+y_sunflower+y_tulip\n",
    "Y = np.array(Y)\n",
    "Y = np.reshape(Y,(Y.shape[0],1))\n",
    "\n",
    "dataAndLabel = []\n",
    "for i in range(Y.shape[0]):\n",
    "    dataAndLabel.append([img_flowers[i],Y[i,0]])\n",
    "    \n",
    "dataAndLabel = np.array(dataAndLabel)\n",
    "\n",
    "##打亂資料排列\n",
    "np.random.seed(110)\n",
    "np.random.shuffle(dataAndLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2258, 256, 256, 3)\n",
      "(2258, 5)\n",
      "(565, 256, 256, 3)\n",
      "(565, 5)\n"
     ]
    }
   ],
   "source": [
    "# Reorganize data and label to X(data) Y(Label). Then Split to X_test X_train, Y_test Y_train\n",
    "# And normalization\n",
    "X_data = []\n",
    "Y_data = []\n",
    "for i in range(Y.shape[0]):\n",
    "    X_data.append(dataAndLabel[i][0])\n",
    "    Y_data.append(dataAndLabel[i][1])\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "Y_data = np.array(Y_data)\n",
    "Y_data = np.reshape(Y_data,(Y_data.shape[0],1))\n",
    "Y_data = to_categorical(Y_data)\n",
    "\n",
    "#normalization\n",
    "X_data =  X_data/255 \n",
    "\n",
    "#Train Test Split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_data,Y_data,test_size=0.20,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定循環類別參數\n",
    "batch_size = 32 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 5 # 類別的數量，共有 5 個類別\n",
    "epochs = 70 # 訓練整個資料集共 30個循環\n",
    "IMAGE_SIZE0 = Downsize\n",
    "IMAGE_SIZE1 = Downsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case1:建立神經網路 這邊直接用ResNet50. 如果要接續訓練，用\n",
    "\n",
    "resnetModel = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE0,IMAGE_SIZE1,3))\n",
    "x = resnetModel.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
    "x = BatchNormalization()(x)\n",
    "#x = Dense(2048, activation='relu', name = \"outputL1\")(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation='relu', name = \"outputL2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
    "\n",
    "resnetModel50 = Model(inputs=resnetModel.input, outputs=output_layer)\n",
    "\n",
    "resnetModel50.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case2: load我之前存好的model繼續訓練 不要跟Case1同時跑\n",
    "resnetModel50 = keras.models.load_model(\"./ML100_Final_Flower.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./ML100_Final_Flower.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "70/70 [==============================] - 3997s 57s/step - loss: 0.6958 - accuracy: 0.7695 - val_loss: 0.8747 - val_accuracy: 0.7009\n",
      "Epoch 2/70\n",
      "70/70 [==============================] - 3944s 56s/step - loss: 0.7451 - accuracy: 0.7381 - val_loss: 0.8925 - val_accuracy: 0.6973\n",
      "Epoch 3/70\n",
      "70/70 [==============================] - 4038s 58s/step - loss: 0.7111 - accuracy: 0.7682 - val_loss: 0.6611 - val_accuracy: 0.7752\n",
      "Epoch 4/70\n",
      "70/70 [==============================] - 4089s 58s/step - loss: 0.6622 - accuracy: 0.7794 - val_loss: 0.7781 - val_accuracy: 0.7504\n",
      "Epoch 5/70\n",
      "70/70 [==============================] - 4244s 61s/step - loss: 0.6344 - accuracy: 0.7808 - val_loss: 0.6836 - val_accuracy: 0.7646\n",
      "Epoch 6/70\n",
      "70/70 [==============================] - 4256s 61s/step - loss: 0.6550 - accuracy: 0.7803 - val_loss: 0.7611 - val_accuracy: 0.7381\n",
      "Epoch 7/70\n",
      "70/70 [==============================] - 4291s 61s/step - loss: 0.6942 - accuracy: 0.7520 - val_loss: 91.4867 - val_accuracy: 0.4177\n",
      "Epoch 8/70\n",
      "70/70 [==============================] - 4311s 62s/step - loss: 0.7858 - accuracy: 0.7278 - val_loss: 13.0798 - val_accuracy: 0.5434\n",
      "Epoch 9/70\n",
      "70/70 [==============================] - 4362s 62s/step - loss: 0.7468 - accuracy: 0.7421 - val_loss: 7.2052 - val_accuracy: 0.4708\n",
      "Epoch 10/70\n",
      "70/70 [==============================] - 4411s 63s/step - loss: 0.7085 - accuracy: 0.7437 - val_loss: 3.0108 - val_accuracy: 0.6248\n",
      "Epoch 11/70\n",
      "70/70 [==============================] - 4351s 62s/step - loss: 0.6259 - accuracy: 0.7780 - val_loss: 0.9330 - val_accuracy: 0.7292\n",
      "Epoch 12/70\n",
      "70/70 [==============================] - 4418s 63s/step - loss: 0.6533 - accuracy: 0.7625 - val_loss: 1.0256 - val_accuracy: 0.6549\n",
      "Epoch 13/70\n",
      "70/70 [==============================] - 4346s 62s/step - loss: 0.6780 - accuracy: 0.7636 - val_loss: 1.8749 - val_accuracy: 0.6478\n",
      "Epoch 14/70\n",
      "70/70 [==============================] - 4394s 63s/step - loss: 0.6471 - accuracy: 0.7754 - val_loss: 5.6655 - val_accuracy: 0.6637\n",
      "Epoch 15/70\n",
      "70/70 [==============================] - 4414s 63s/step - loss: 0.5704 - accuracy: 0.8046 - val_loss: 1.9139 - val_accuracy: 0.7327\n",
      "Epoch 16/70\n",
      "70/70 [==============================] - 4409s 63s/step - loss: 0.6158 - accuracy: 0.7812 - val_loss: 2.6276 - val_accuracy: 0.7310\n",
      "Epoch 17/70\n",
      "70/70 [==============================] - 4406s 63s/step - loss: 0.6655 - accuracy: 0.7691 - val_loss: 0.8090 - val_accuracy: 0.7044\n",
      "Epoch 18/70\n",
      "70/70 [==============================] - 4446s 64s/step - loss: 0.6718 - accuracy: 0.7652 - val_loss: 1.6047 - val_accuracy: 0.7115\n",
      "Epoch 19/70\n",
      "70/70 [==============================] - 4360s 62s/step - loss: 0.5790 - accuracy: 0.7988 - val_loss: 1.7270 - val_accuracy: 0.6885\n",
      "Epoch 20/70\n",
      "70/70 [==============================] - 4480s 64s/step - loss: 0.5858 - accuracy: 0.7929 - val_loss: 2.0374 - val_accuracy: 0.6991\n",
      "Epoch 21/70\n",
      "70/70 [==============================] - 4436s 63s/step - loss: 0.5490 - accuracy: 0.8122 - val_loss: 2.2743 - val_accuracy: 0.6903\n",
      "Epoch 22/70\n",
      "44/70 [=================>............] - ETA: 26:17 - loss: 0.5351 - accuracy: 0.8068"
     ]
    }
   ],
   "source": [
    "# Train Model using image augment generator\n",
    "#epochs = 70\n",
    "\n",
    "augment_generator = ImageDataGenerator(rotation_range=40, width_shift_range=0.4, height_shift_range=0.4, shear_range=0.2,\n",
    "    zoom_range=0.3,horizontal_flip=True)\n",
    "\n",
    "history = resnetModel50.fit_generator(augment_generator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train)/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[model_ckpt])\n",
    "\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "score = resnetModel50.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save latest model for furthr trainning\n",
    "#resnetModel50.save(\"ML100_Final_Flower_latest.h5\")\n",
    "\n",
    "#Or Load Model to test\n",
    "#resnetModel50 = keras.models.load_model(\"./ML100_Final_Flower_latest.h5\") #latest model\n",
    "resnetModel50 = keras.models.load_model(\"./ML100_Final_Flower.h5\") # Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test Data, Normalization and predict\n",
    "#TestModel = keras.models.load_model(\"./ML100_Final_Flower.h5\")\n",
    "path_testImg = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/test/'\n",
    "testImg = os.listdir(path_testImg)\n",
    "#img_test = np.zeros((len(testImg),1))\n",
    "img_test = []\n",
    "Downsize = 256\n",
    "\n",
    "i = 0\n",
    "for i in range(len(testImg)):\n",
    "    pic = cv2.imread(path_testImg+testImg[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_test.append(pic)\n",
    "\n",
    "img_test = np.array(img_test)\n",
    "img_test = img_test/255\n",
    "\n",
    "pred = resnetModel50.predict(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7468415e-02 6.0330154e-03 8.7225425e-01 8.4274355e-03 9.5816866e-02]\n",
      " [1.8978843e-02 4.0312104e-02 6.2691256e-02 2.4774894e-02 8.5324287e-01]\n",
      " [1.6956350e-03 6.5342046e-04 9.1229945e-01 4.3783397e-03 8.0973104e-02]\n",
      " ...\n",
      " [9.9642605e-01 1.5503658e-05 2.8585012e-03 2.3699409e-04 4.6291997e-04]\n",
      " [4.2249519e-02 9.2686899e-02 4.1679449e-02 6.7655069e-01 1.4683346e-01]\n",
      " [8.6006457e-03 2.3005197e-03 4.5166206e-01 9.1225776e-04 5.3652453e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "pred_forsave = np.argmax(pred, axis=1)\n",
    "#print(pred_forsave)\n",
    "#print(testImg)\n",
    "testImgId = []\n",
    "for x in testImg:\n",
    "    testImgId.append(os.path.splitext(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV file for submission\n",
    "subcsv = pd.DataFrame({'id': testImgId, 'flower_class': pred_forsave})\n",
    "subcsv.to_csv('ml100FinalSub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
