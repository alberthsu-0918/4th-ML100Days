{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loda image\n",
    "path_daisy = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/daisy/'\n",
    "path_dandelion = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/dandelion/'\n",
    "path_rose = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/rose/'\n",
    "path_sunflower = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/sunflower/'\n",
    "path_tulip = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/tulip/'\n",
    "\n",
    "\n",
    "daisy = os.listdir(path_daisy)\n",
    "dandelion = os.listdir(path_dandelion)\n",
    "rose = os.listdir(path_rose)\n",
    "sunflower = os.listdir(path_sunflower)\n",
    "tulip = os.listdir(path_tulip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crate Lable array y \n",
    "y_daisy = [0]*len(daisy)\n",
    "y_dandelion = [1]*len(dandelion)\n",
    "y_rose = [2]*len(rose)\n",
    "y_sunflower = [3]*len(sunflower)\n",
    "y_tulip = [4]*len(tulip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823\n"
     ]
    }
   ],
   "source": [
    "#Load image to arrays\n",
    "img_flowers = []\n",
    "img_dandelion = np.zeros((len(dandelion),1))\n",
    "img_rose = np.zeros((len(rose),1))\n",
    "img_sunflower = np.zeros((len(sunflower),1))\n",
    "img_tulip = np.zeros((len(tulip),1))\n",
    "\n",
    "Downsize = 256\n",
    "\n",
    "i = 0\n",
    "for i in range(len(daisy)):\n",
    "    pic = cv2.imread(path_daisy+daisy[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(dandelion)):\n",
    "    pic = cv2.imread(path_dandelion+dandelion[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(rose)):\n",
    "    pic = cv2.imread(path_rose+rose[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(sunflower)):\n",
    "    pic = cv2.imread(path_sunflower+sunflower[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(tulip)):\n",
    "    pic = cv2.imread(path_tulip+tulip[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "\n",
    "    \n",
    "print(len(img_flowers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data(img_flowers) and Label(y___)\n",
    "\n",
    "Y = y_daisy+y_dandelion+y_rose+y_sunflower+y_tulip\n",
    "Y = np.array(Y)\n",
    "Y = np.reshape(Y,(Y.shape[0],1))\n",
    "\n",
    "dataAndLabel = []\n",
    "for i in range(Y.shape[0]):\n",
    "    dataAndLabel.append([img_flowers[i],Y[i,0]])\n",
    "    \n",
    "dataAndLabel = np.array(dataAndLabel)\n",
    "\n",
    "##打亂資料排列\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(dataAndLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2258, 256, 256, 3)\n",
      "(2258, 5)\n",
      "(565, 256, 256, 3)\n",
      "(565, 5)\n"
     ]
    }
   ],
   "source": [
    "# Reorganize data and label to X(data) Y(Label). Then Split to X_test X_train, Y_test Y_train\n",
    "# And normalization\n",
    "X_data = []\n",
    "Y_data = []\n",
    "for i in range(Y.shape[0]):\n",
    "    X_data.append(dataAndLabel[i][0])\n",
    "    Y_data.append(dataAndLabel[i][1])\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "Y_data = np.array(Y_data)\n",
    "Y_data = np.reshape(Y_data,(Y_data.shape[0],1))\n",
    "Y_data = to_categorical(Y_data)\n",
    "\n",
    "#normalization\n",
    "X_data =  X_data/255 \n",
    "\n",
    "#Train Test Split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_data,Y_data,test_size=0.20,random_state=23) #random_state=42 for 1st round\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定循環類別參數\n",
    "batch_size = 32 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 5 # 類別的數量，共有 5 個類別\n",
    "epochs = 70 # 訓練整個資料集共 30個循環\n",
    "IMAGE_SIZE0 = Downsize\n",
    "IMAGE_SIZE1 = Downsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case1:建立神經網路 這邊直接用ResNet50. 如果要接續訓練，用\n",
    "\n",
    "resnetModel = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE0,IMAGE_SIZE1,3))\n",
    "x = resnetModel.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
    "x = BatchNormalization()(x)\n",
    "#x = Dense(2048, activation='relu', name = \"outputL1\")(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation='relu', name = \"outputL2\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
    "\n",
    "resnetModel50 = Model(inputs=resnetModel.input, outputs=output_layer)\n",
    "\n",
    "resnetModel50.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case2: load我之前存好的model繼續訓練 不要跟Case1同時跑\n",
    "#resnetModel50 = keras.models.load_model(\"./ML100_Final_Flower_latest.h5\") #latest model\n",
    "resnetModel50 = keras.models.load_model(\"./ML100_Final_Flower_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./ML100_Final_Flower_2.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "70/70 [==============================] - 3880s 55s/step - loss: 0.3455 - accuracy: 0.8706 - val_loss: 0.3118 - val_accuracy: 0.8885\n",
      "Epoch 2/50\n",
      "70/70 [==============================] - 3854s 55s/step - loss: 0.3195 - accuracy: 0.8859 - val_loss: 0.3940 - val_accuracy: 0.8496\n",
      "Epoch 3/50\n",
      "70/70 [==============================] - 3917s 56s/step - loss: 0.2878 - accuracy: 0.8958 - val_loss: 0.3514 - val_accuracy: 0.8796\n",
      "Epoch 4/50\n",
      "70/70 [==============================] - 3976s 57s/step - loss: 0.3472 - accuracy: 0.8823 - val_loss: 0.3382 - val_accuracy: 0.8867\n",
      "Epoch 5/50\n",
      "70/70 [==============================] - 3938s 56s/step - loss: 0.3029 - accuracy: 0.8967 - val_loss: 0.6505 - val_accuracy: 0.8319\n",
      "Epoch 6/50\n",
      "70/70 [==============================] - 3998s 57s/step - loss: 0.2841 - accuracy: 0.9039 - val_loss: 0.2760 - val_accuracy: 0.9009\n",
      "Epoch 7/50\n",
      "70/70 [==============================] - 4012s 57s/step - loss: 0.2831 - accuracy: 0.9043 - val_loss: 0.8857 - val_accuracy: 0.7646\n",
      "Epoch 8/50\n",
      "70/70 [==============================] - 4013s 57s/step - loss: 0.2558 - accuracy: 0.9070 - val_loss: 0.4239 - val_accuracy: 0.8708\n",
      "Epoch 9/50\n",
      "70/70 [==============================] - 4028s 58s/step - loss: 0.2552 - accuracy: 0.9106 - val_loss: 0.4280 - val_accuracy: 0.8531\n",
      "Epoch 10/50\n",
      "70/70 [==============================] - 4082s 58s/step - loss: 0.2993 - accuracy: 0.8942 - val_loss: 2.6341 - val_accuracy: 0.4726\n",
      "Epoch 11/50\n",
      "70/70 [==============================] - 4039s 58s/step - loss: 0.3492 - accuracy: 0.8761 - val_loss: 0.7560 - val_accuracy: 0.7681\n",
      "Epoch 12/50\n",
      "70/70 [==============================] - 4127s 59s/step - loss: 0.2524 - accuracy: 0.9134 - val_loss: 0.4049 - val_accuracy: 0.8478\n",
      "Epoch 13/50\n",
      "70/70 [==============================] - 4059s 58s/step - loss: 0.3033 - accuracy: 0.8965 - val_loss: 0.3809 - val_accuracy: 0.8602\n",
      "Epoch 14/50\n",
      "70/70 [==============================] - 4096s 59s/step - loss: 0.2595 - accuracy: 0.9146 - val_loss: 0.3715 - val_accuracy: 0.8637\n",
      "Epoch 15/50\n",
      "70/70 [==============================] - 4093s 58s/step - loss: 0.2602 - accuracy: 0.9075 - val_loss: 0.8858 - val_accuracy: 0.7097\n",
      "Epoch 16/50\n",
      "70/70 [==============================] - 4082s 58s/step - loss: 0.2658 - accuracy: 0.9039 - val_loss: 0.4179 - val_accuracy: 0.8602\n",
      "Epoch 17/50\n",
      "70/70 [==============================] - 4128s 59s/step - loss: 0.2228 - accuracy: 0.9223 - val_loss: 0.3588 - val_accuracy: 0.8726\n",
      "Epoch 18/50\n",
      "70/70 [==============================] - 4107s 59s/step - loss: 0.2476 - accuracy: 0.9088 - val_loss: 1.1433 - val_accuracy: 0.6796\n",
      "Epoch 19/50\n",
      "70/70 [==============================] - 4106s 59s/step - loss: 0.2152 - accuracy: 0.9232 - val_loss: 0.5498 - val_accuracy: 0.8301\n",
      "Epoch 20/50\n",
      "70/70 [==============================] - 4088s 58s/step - loss: 0.2242 - accuracy: 0.9218 - val_loss: 0.4440 - val_accuracy: 0.8496\n",
      "Epoch 21/50\n",
      "70/70 [==============================] - 4138s 59s/step - loss: 0.2108 - accuracy: 0.9322 - val_loss: 0.2993 - val_accuracy: 0.8956\n",
      "Epoch 22/50\n",
      "70/70 [==============================] - 4139s 59s/step - loss: 0.2060 - accuracy: 0.9304 - val_loss: 0.4934 - val_accuracy: 0.8336\n",
      "Epoch 23/50\n",
      "70/70 [==============================] - 4180s 60s/step - loss: 0.2224 - accuracy: 0.9232 - val_loss: 0.5936 - val_accuracy: 0.8159\n",
      "Epoch 24/50\n",
      "70/70 [==============================] - 4185s 60s/step - loss: 0.2204 - accuracy: 0.9286 - val_loss: 0.5245 - val_accuracy: 0.8478\n",
      "Epoch 25/50\n",
      "70/70 [==============================] - 4163s 59s/step - loss: 0.1785 - accuracy: 0.9304 - val_loss: 1.3254 - val_accuracy: 0.7009\n",
      "Epoch 26/50\n",
      "70/70 [==============================] - 4139s 59s/step - loss: 0.2461 - accuracy: 0.9155 - val_loss: 0.4256 - val_accuracy: 0.8407\n",
      "Epoch 27/50\n",
      "70/70 [==============================] - 4165s 60s/step - loss: 0.2143 - accuracy: 0.9201 - val_loss: 0.5089 - val_accuracy: 0.8460\n",
      "Epoch 28/50\n",
      "70/70 [==============================] - 4160s 59s/step - loss: 0.1757 - accuracy: 0.9340 - val_loss: 0.6323 - val_accuracy: 0.8053\n",
      "Epoch 29/50\n",
      "70/70 [==============================] - 4117s 59s/step - loss: 0.2017 - accuracy: 0.9331 - val_loss: 0.4630 - val_accuracy: 0.8442\n",
      "Epoch 30/50\n",
      "70/70 [==============================] - 4158s 59s/step - loss: 0.2016 - accuracy: 0.9322 - val_loss: 0.4838 - val_accuracy: 0.8478\n",
      "Epoch 31/50\n",
      "70/70 [==============================] - 4167s 60s/step - loss: 0.2045 - accuracy: 0.9272 - val_loss: 0.9463 - val_accuracy: 0.6867\n",
      "Epoch 32/50\n",
      "70/70 [==============================] - 4136s 59s/step - loss: 0.2733 - accuracy: 0.9137 - val_loss: 0.5441 - val_accuracy: 0.8478\n",
      "Epoch 33/50\n",
      "70/70 [==============================] - 4177s 60s/step - loss: 0.2315 - accuracy: 0.9201 - val_loss: 0.6405 - val_accuracy: 0.8265\n",
      "Epoch 34/50\n",
      "70/70 [==============================] - 4134s 59s/step - loss: 0.1678 - accuracy: 0.9367 - val_loss: 0.6406 - val_accuracy: 0.7965\n",
      "Epoch 35/50\n",
      "70/70 [==============================] - 4225s 60s/step - loss: 0.1817 - accuracy: 0.9397 - val_loss: 0.5314 - val_accuracy: 0.8442\n",
      "Epoch 36/50\n",
      "70/70 [==============================] - 4107s 59s/step - loss: 0.1854 - accuracy: 0.9313 - val_loss: 0.5829 - val_accuracy: 0.8513\n",
      "Epoch 37/50\n",
      "70/70 [==============================] - 4163s 59s/step - loss: 0.1751 - accuracy: 0.9393 - val_loss: 0.4482 - val_accuracy: 0.8619\n",
      "Epoch 38/50\n",
      "70/70 [==============================] - 4149s 59s/step - loss: 0.1908 - accuracy: 0.9385 - val_loss: 0.4615 - val_accuracy: 0.8708\n",
      "Epoch 39/50\n",
      "70/70 [==============================] - 4184s 60s/step - loss: 0.1912 - accuracy: 0.9385 - val_loss: 0.3944 - val_accuracy: 0.8726\n",
      "Epoch 40/50\n",
      "70/70 [==============================] - 4154s 59s/step - loss: 0.1962 - accuracy: 0.9317 - val_loss: 0.5195 - val_accuracy: 0.8513\n",
      "Epoch 41/50\n",
      "70/70 [==============================] - 4198s 60s/step - loss: 0.1739 - accuracy: 0.9389 - val_loss: 0.3991 - val_accuracy: 0.8566\n",
      "Epoch 42/50\n",
      "70/70 [==============================] - 4184s 60s/step - loss: 0.1764 - accuracy: 0.9416 - val_loss: 0.5140 - val_accuracy: 0.8354\n",
      "Epoch 43/50\n",
      "70/70 [==============================] - 4178s 60s/step - loss: 0.1585 - accuracy: 0.9480 - val_loss: 0.6633 - val_accuracy: 0.8265\n",
      "Epoch 44/50\n",
      "70/70 [==============================] - 4223s 60s/step - loss: 0.1595 - accuracy: 0.9348 - val_loss: 0.5209 - val_accuracy: 0.8425\n",
      "Epoch 45/50\n",
      "70/70 [==============================] - 4128s 59s/step - loss: 0.1833 - accuracy: 0.9389 - val_loss: 0.5537 - val_accuracy: 0.8354\n",
      "Epoch 46/50\n",
      "70/70 [==============================] - 4348s 62s/step - loss: 0.1581 - accuracy: 0.9488 - val_loss: 0.5721 - val_accuracy: 0.8265\n",
      "Epoch 47/50\n",
      "70/70 [==============================] - 4295s 61s/step - loss: 0.1566 - accuracy: 0.9465 - val_loss: 0.6477 - val_accuracy: 0.8407\n",
      "Epoch 48/50\n",
      "70/70 [==============================] - 4183s 60s/step - loss: 0.1620 - accuracy: 0.9474 - val_loss: 1.6577 - val_accuracy: 0.7770\n",
      "Epoch 49/50\n",
      "70/70 [==============================] - 4219s 60s/step - loss: 0.2337 - accuracy: 0.9164 - val_loss: 0.8391 - val_accuracy: 0.8035\n",
      "Epoch 50/50\n",
      "70/70 [==============================] - 4223s 60s/step - loss: 0.1807 - accuracy: 0.9389 - val_loss: 0.5725 - val_accuracy: 0.8496\n",
      "Test loss: 0.5725256332781462\n",
      "Test accuracy: 0.8495575189590454\n"
     ]
    }
   ],
   "source": [
    "# Train Model using image augment generator\n",
    "epochs = 50\n",
    "\n",
    "augment_generator = ImageDataGenerator(rotation_range=30, width_shift_range=0.3, height_shift_range=0.3, shear_range=0.2,\n",
    "    zoom_range=0.3,horizontal_flip=True)\n",
    "\n",
    "history = resnetModel50.fit_generator(augment_generator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train)/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[model_ckpt])\n",
    "\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "score = resnetModel50.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save latest model for furthr trainning\n",
    "#resnetModel50.save(\"ML100_Final_Flower_latest.h5\")\n",
    "\n",
    "#Or Load Model to test\n",
    "#resnetModel50 = keras.models.load_model(\"./ML100_Final_Flower_latest.h5\") #latest model\n",
    "#resnetModel50 = keras.models.load_model(\"./ML100_Final_Flower.h5\") # Best model\n",
    "resnetModel50 = keras.models.load_model(\"./FinalP_Flower_aug_1.h5\") # Best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test Data, Normalization and predict\n",
    "#TestModel = keras.models.load_model(\"./ML100_Final_Flower.h5\")\n",
    "path_testImg = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/test/'\n",
    "testImg = os.listdir(path_testImg)\n",
    "#img_test = np.zeros((len(testImg),1))\n",
    "img_test = []\n",
    "#Downsize = 256\n",
    "Downsize = 128\n",
    "\n",
    "i = 0\n",
    "for i in range(len(testImg)):\n",
    "    pic = cv2.imread(path_testImg+testImg[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_test.append(pic)\n",
    "\n",
    "img_test = np.array(img_test)\n",
    "img_test = img_test/255\n",
    "\n",
    "pred = resnetModel50.predict(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7468415e-02 6.0330154e-03 8.7225425e-01 8.4274355e-03 9.5816866e-02]\n",
      " [1.8978843e-02 4.0312104e-02 6.2691256e-02 2.4774894e-02 8.5324287e-01]\n",
      " [1.6956350e-03 6.5342046e-04 9.1229945e-01 4.3783397e-03 8.0973104e-02]\n",
      " ...\n",
      " [9.9642605e-01 1.5503658e-05 2.8585012e-03 2.3699409e-04 4.6291997e-04]\n",
      " [4.2249519e-02 9.2686899e-02 4.1679449e-02 6.7655069e-01 1.4683346e-01]\n",
      " [8.6006457e-03 2.3005197e-03 4.5166206e-01 9.1225776e-04 5.3652453e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "pred_forsave = np.argmax(pred, axis=1)\n",
    "#print(pred_forsave)\n",
    "#print(testImg)\n",
    "testImgId = []\n",
    "for x in testImg:\n",
    "    testImgId.append(os.path.splitext(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV file for submission\n",
    "subcsv = pd.DataFrame({'id': testImgId, 'flower_class': pred_forsave})\n",
    "subcsv.to_csv('ml100FinalSub3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
