{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 範例重點\n",
    "* 了解如何 reset Tensorflow Graph\n",
    "* 學習如何以迴圈方式訓練不同超參數的模型\n",
    "* 學習如何以迴圈方式繪圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本範例不需使用 GPU, 將 GPU 設定為 \"無\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# 資料前處理 - X 標準化\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# 資料前處理 -Y 轉成 onehot\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.100000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 22s 444us/step - loss: 2.3211 - accuracy: 0.1025 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 2.3041 - accuracy: 0.1020 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 2.3042 - accuracy: 0.0995 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 2.3042 - accuracy: 0.0993 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 2.3045 - accuracy: 0.1004 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 2.3040 - accuracy: 0.0992 - val_loss: 2.3041 - val_accuracy: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 2.3042 - accuracy: 0.0976 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 2.3040 - accuracy: 0.1019 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 2.3041 - accuracy: 0.1015 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 2.3043 - accuracy: 0.0978 - val_loss: 2.3067 - val_accuracy: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 2.3046 - accuracy: 0.1003 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 2.3038 - accuracy: 0.1016 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 22s 440us/step - loss: 2.3042 - accuracy: 0.1014 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 2.3042 - accuracy: 0.0980 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 2.3041 - accuracy: 0.1010 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 2.3044 - accuracy: 0.0986 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 2.3042 - accuracy: 0.1020 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 2.3042 - accuracy: 0.1002 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 2.3043 - accuracy: 0.1011 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 2.3043 - accuracy: 0.1017 - val_loss: 2.3046 - val_accuracy: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 2.3041 - accuracy: 0.0991 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 2.3038 - accuracy: 0.1034 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 24s 477us/step - loss: 2.3040 - accuracy: 0.1000 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 22s 442us/step - loss: 2.3040 - accuracy: 0.0994 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 2.3039 - accuracy: 0.0999 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 2.3044 - accuracy: 0.0986 - val_loss: 2.3055 - val_accuracy: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 2.3041 - accuracy: 0.1006 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 2.3042 - accuracy: 0.0999 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 2.3044 - accuracy: 0.0991 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 2.3042 - accuracy: 0.0998 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 2.3044 - accuracy: 0.0998 - val_loss: 2.3044 - val_accuracy: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 2.3045 - accuracy: 0.0970 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 2.3039 - accuracy: 0.1002 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.3040 - accuracy: 0.1016 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 2.3042 - accuracy: 0.0993 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 2.3043 - accuracy: 0.1014 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 2.3040 - accuracy: 0.0980 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 2.3042 - accuracy: 0.0981 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 2.3043 - accuracy: 0.0999 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 2.3040 - accuracy: 0.0994 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 2.3044 - accuracy: 0.1007 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 2.3043 - accuracy: 0.0961 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 2.3044 - accuracy: 0.1005 - val_loss: 2.3047 - val_accuracy: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 2.3045 - accuracy: 0.0987 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 2.3043 - accuracy: 0.1013 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 2.3042 - accuracy: 0.0986 - val_loss: 2.3051 - val_accuracy: 0.1000\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 21s 419us/step - loss: 2.3044 - accuracy: 0.0989 - val_loss: 2.3049 - val_accuracy: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 2.3044 - accuracy: 0.0978 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 2.3042 - accuracy: 0.0972 - val_loss: 2.3045 - val_accuracy: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 2.3044 - accuracy: 0.0995 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Experiment with LR = 0.010000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 1.8289 - accuracy: 0.3444 - val_loss: 1.6627 - val_accuracy: 0.4129\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.5979 - accuracy: 0.4336 - val_loss: 1.5966 - val_accuracy: 0.4330\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.5079 - accuracy: 0.4611 - val_loss: 1.5072 - val_accuracy: 0.4591\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 1.4500 - accuracy: 0.4837 - val_loss: 1.4840 - val_accuracy: 0.4643\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.4005 - accuracy: 0.5030 - val_loss: 1.5113 - val_accuracy: 0.4708\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.3618 - accuracy: 0.5172 - val_loss: 1.4148 - val_accuracy: 0.4933\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.3291 - accuracy: 0.5239 - val_loss: 1.4195 - val_accuracy: 0.4964\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.2916 - accuracy: 0.5406 - val_loss: 1.3735 - val_accuracy: 0.5070\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 1.2586 - accuracy: 0.5523 - val_loss: 1.3924 - val_accuracy: 0.5037\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 1.2305 - accuracy: 0.5610 - val_loss: 1.3745 - val_accuracy: 0.5156\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.2007 - accuracy: 0.5721 - val_loss: 1.3565 - val_accuracy: 0.5195\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 1.1660 - accuracy: 0.5866 - val_loss: 1.3694 - val_accuracy: 0.5176\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 1.1441 - accuracy: 0.5909 - val_loss: 1.4194 - val_accuracy: 0.5071\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 1.1219 - accuracy: 0.5997 - val_loss: 1.3771 - val_accuracy: 0.5142\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 1.0913 - accuracy: 0.6091 - val_loss: 1.3897 - val_accuracy: 0.5179\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 1.0670 - accuracy: 0.6183 - val_loss: 1.3433 - val_accuracy: 0.5377\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 22s 441us/step - loss: 1.0394 - accuracy: 0.6288 - val_loss: 1.4186 - val_accuracy: 0.5141\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.0099 - accuracy: 0.6394 - val_loss: 1.3671 - val_accuracy: 0.5283\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.9914 - accuracy: 0.6453 - val_loss: 1.3792 - val_accuracy: 0.5237\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 22s 444us/step - loss: 0.9638 - accuracy: 0.6561 - val_loss: 1.4370 - val_accuracy: 0.5234\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.9484 - accuracy: 0.6611 - val_loss: 1.3730 - val_accuracy: 0.5353\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 22s 440us/step - loss: 0.9184 - accuracy: 0.6712 - val_loss: 1.4272 - val_accuracy: 0.5288\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.9023 - accuracy: 0.6779 - val_loss: 1.4214 - val_accuracy: 0.5237\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 22s 431us/step - loss: 0.8716 - accuracy: 0.6866 - val_loss: 1.4254 - val_accuracy: 0.5343\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 0.8486 - accuracy: 0.6943 - val_loss: 1.4112 - val_accuracy: 0.5380\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 0.8176 - accuracy: 0.7060 - val_loss: 1.4535 - val_accuracy: 0.5372\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.8140 - accuracy: 0.7085 - val_loss: 1.6110 - val_accuracy: 0.5110\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 0.7882 - accuracy: 0.7182 - val_loss: 1.5242 - val_accuracy: 0.5225\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.7595 - accuracy: 0.7280 - val_loss: 1.5156 - val_accuracy: 0.5275\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.7393 - accuracy: 0.7356 - val_loss: 1.5895 - val_accuracy: 0.5253\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 0.7189 - accuracy: 0.7403 - val_loss: 1.6688 - val_accuracy: 0.5071\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 0.6927 - accuracy: 0.7510 - val_loss: 1.5827 - val_accuracy: 0.5208\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 0.6601 - accuracy: 0.7622 - val_loss: 1.6779 - val_accuracy: 0.5263\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.6414 - accuracy: 0.7713 - val_loss: 1.6146 - val_accuracy: 0.5313\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 0.6260 - accuracy: 0.7748 - val_loss: 1.7100 - val_accuracy: 0.5271\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.6022 - accuracy: 0.7855 - val_loss: 1.7217 - val_accuracy: 0.5273\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.5816 - accuracy: 0.7908 - val_loss: 1.8197 - val_accuracy: 0.5121\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.5700 - accuracy: 0.7954 - val_loss: 1.7519 - val_accuracy: 0.5216\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.5442 - accuracy: 0.8045 - val_loss: 1.8743 - val_accuracy: 0.5292\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 0.5326 - accuracy: 0.8077 - val_loss: 1.8440 - val_accuracy: 0.5317\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 0.5227 - accuracy: 0.8120 - val_loss: 1.9021 - val_accuracy: 0.5221\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.5019 - accuracy: 0.8180 - val_loss: 2.0192 - val_accuracy: 0.5154\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 0.4811 - accuracy: 0.8269 - val_loss: 1.9329 - val_accuracy: 0.5251\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 21s 420us/step - loss: 0.4600 - accuracy: 0.8331 - val_loss: 1.9645 - val_accuracy: 0.5179\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 0.4456 - accuracy: 0.8392 - val_loss: 2.0291 - val_accuracy: 0.5277\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.4244 - accuracy: 0.8460 - val_loss: 2.0286 - val_accuracy: 0.5260\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.4195 - accuracy: 0.8475 - val_loss: 2.1013 - val_accuracy: 0.5271\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 20s 405us/step - loss: 0.4037 - accuracy: 0.8550 - val_loss: 2.1908 - val_accuracy: 0.5217\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.3945 - accuracy: 0.8588 - val_loss: 2.2337 - val_accuracy: 0.5127\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 0.3779 - accuracy: 0.8627 - val_loss: 2.3028 - val_accuracy: 0.5194\n",
      "Experiment with LR = 0.001000\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 2.0484 - accuracy: 0.2659 - val_loss: 1.8868 - val_accuracy: 0.3268\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.8282 - accuracy: 0.3557 - val_loss: 1.7810 - val_accuracy: 0.3743\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 1.7467 - accuracy: 0.3886 - val_loss: 1.7156 - val_accuracy: 0.3936\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 1.6886 - accuracy: 0.4067 - val_loss: 1.6755 - val_accuracy: 0.4119\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 1.6405 - accuracy: 0.4242 - val_loss: 1.6308 - val_accuracy: 0.4254\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 1.6024 - accuracy: 0.4384 - val_loss: 1.5908 - val_accuracy: 0.4370\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 1.5667 - accuracy: 0.4510 - val_loss: 1.5617 - val_accuracy: 0.4502\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 1.5364 - accuracy: 0.4611 - val_loss: 1.5397 - val_accuracy: 0.4581\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 1.5094 - accuracy: 0.4693 - val_loss: 1.5267 - val_accuracy: 0.4652\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 1.4811 - accuracy: 0.4812 - val_loss: 1.4953 - val_accuracy: 0.4697\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 1.4574 - accuracy: 0.4885 - val_loss: 1.4890 - val_accuracy: 0.4707\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 21s 429us/step - loss: 1.4318 - accuracy: 0.4989 - val_loss: 1.4718 - val_accuracy: 0.4772\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.4104 - accuracy: 0.5043 - val_loss: 1.4531 - val_accuracy: 0.4818\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 1.3882 - accuracy: 0.5113 - val_loss: 1.4380 - val_accuracy: 0.4862\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 21s 419us/step - loss: 1.3693 - accuracy: 0.5168 - val_loss: 1.4308 - val_accuracy: 0.4919\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 1.3492 - accuracy: 0.5249 - val_loss: 1.4132 - val_accuracy: 0.4943\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 1.3299 - accuracy: 0.5311 - val_loss: 1.4128 - val_accuracy: 0.5007\n",
      "Epoch 18/50\n",
      "42496/50000 [========================>.....] - ETA: 2s - loss: 1.3087 - accuracy: 0.53"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"\n",
    "使用迴圈，建立不同 Learning rate 的模型並訓練\n",
    "\"\"\"\n",
    "for lr in LEARNING_RATE:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with LR = %.6f\" % (lr))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"accuracy\"]\n",
    "    valid_acc = model.history.history[\"val_accuracy\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-lr-%s\" % str(lr)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較 SGD optimizer 不同的 momentum 及使用 nesterov 與否的表現"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
