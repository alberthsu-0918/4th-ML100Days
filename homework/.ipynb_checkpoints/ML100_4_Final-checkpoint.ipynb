{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras\n",
    "from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loda image\n",
    "path_daisy = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/daisy/'\n",
    "path_dandelion = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/dandelion/'\n",
    "path_rose = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/rose/'\n",
    "path_sunflower = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/sunflower/'\n",
    "path_tulip = 'C:/Users/AlbertHsu/Documents/GitHub/4th-ML100Days/homework/Data/image_data/train/tulip/'\n",
    "\n",
    "daisy = os.listdir(path_daisy)\n",
    "dandelion = os.listdir(path_dandelion)\n",
    "rose = os.listdir(path_rose)\n",
    "sunflower = os.listdir(path_sunflower)\n",
    "tulip = os.listdir(path_tulip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crate Lable array y \n",
    "y_daisy = [0]*len(daisy)\n",
    "y_dandelion = [1]*len(dandelion)\n",
    "y_rose = [2]*len(rose)\n",
    "y_sunflower = [3]*len(sunflower)\n",
    "y_tulip = [4]*len(tulip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823\n"
     ]
    }
   ],
   "source": [
    "#Load image to arrays\n",
    "img_flowers = []\n",
    "img_dandelion = np.zeros((len(dandelion),1))\n",
    "img_rose = np.zeros((len(rose),1))\n",
    "img_sunflower = np.zeros((len(sunflower),1))\n",
    "img_tulip = np.zeros((len(tulip),1))\n",
    "Downsize = 128\n",
    "\n",
    "i = 0\n",
    "for i in range(len(daisy)):\n",
    "    pic = cv2.imread(path_daisy+daisy[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(dandelion)):\n",
    "    pic = cv2.imread(path_dandelion+dandelion[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(rose)):\n",
    "    pic = cv2.imread(path_rose+rose[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(sunflower)):\n",
    "    pic = cv2.imread(path_sunflower+sunflower[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "i = 0\n",
    "for i in range(len(tulip)):\n",
    "    pic = cv2.imread(path_tulip+tulip[i])\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(Downsize,Downsize))\n",
    "    img_flowers.append(pic)\n",
    "    \n",
    "print(len(img_flowers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data(img_flowers) and Label(y___)\n",
    "\n",
    "Y = y_daisy+y_dandelion+y_rose+y_sunflower+y_tulip\n",
    "Y = np.array(Y)\n",
    "Y = np.reshape(Y,(Y.shape[0],1))\n",
    "\n",
    "dataAndLabel = []\n",
    "for i in range(Y.shape[0]):\n",
    "    dataAndLabel.append([img_flowers[i],Y[i,0]])\n",
    "    \n",
    "dataAndLabel = np.array(dataAndLabel)\n",
    "\n",
    "##打亂資料排列\n",
    "np.random.seed(110)\n",
    "np.random.shuffle(dataAndLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2258, 128, 128, 3)\n",
      "(2258, 5)\n",
      "(565, 128, 128, 3)\n",
      "(565, 5)\n"
     ]
    }
   ],
   "source": [
    "# Reorganize data and label to X(data) Y(Label). Then Split to X_test X_train, Y_test Y_train\n",
    "# And normalization\n",
    "X_data = []\n",
    "Y_data = []\n",
    "for i in range(Y.shape[0]):\n",
    "    X_data.append(dataAndLabel[i][0])\n",
    "    Y_data.append(dataAndLabel[i][1])\n",
    "\n",
    "X_data = np.array(X_data)\n",
    "Y_data = np.array(Y_data)\n",
    "Y_data = np.reshape(Y_data,(Y_data.shape[0],1))\n",
    "Y_data = to_categorical(Y_data)\n",
    "\n",
    "#normalization\n",
    "X_data =  X_data/255 \n",
    "\n",
    "#Train Test Split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_data,Y_data,test_size=0.20,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定循環類別參數\n",
    "batch_size = 32 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 5 # 類別的數量，共有 5 個類別\n",
    "epochs = 10 # 訓練整個資料集共 30個循環\n",
    "IMAGE_SIZE0 = Downsize\n",
    "IMAGE_SIZE1 = Downsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlbertHsu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "# Case1:建立神經網路 這邊直接用ResNet50. 如果要接續訓練，用\n",
    "\n",
    "resnetModel = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE0,IMAGE_SIZE1,3))\n",
    "x = resnetModel.output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
    "output_layer = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
    "\n",
    "resnetModel50 = Model(inputs=resnetModel.input, outputs=output_layer)\n",
    "\n",
    "resnetModel50.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case2: load我之前存好的model繼續訓練 不要跟Case1同時跑\n",
    "resnetModel50 = keras.models.load_model(\"./FinalP_Flower_aug_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_ckpt = ModelCheckpoint(filepath=\"./ML100_Final_Flower.h5\", \n",
    "                             monitor=\"val_loss\", \n",
    "                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model using image augment generator\n",
    "augment_generator = ImageDataGenerator(rotation_range=40, width_shift_range=0.4, height_shift_range=0.4, shear_range=0.2,\n",
    "    zoom_range=0.3,horizontal_flip=True)\n",
    "\n",
    "history = resnetModel50.fit_generator(augment_generator.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(len(x_train)/batch_size), # 一個 epochs 要執行幾次 update，通常是資料量除以 batch size\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[model_ckpt])\n",
    "\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "score = resnetModel50.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
